[{"chunk": "While memory costs (for raw samples) are almost always constrained, computational costs are much less so. Sometimes simply discussing that there is (almost) no additional computational cost can suffice, yet it is remarkable that in more than 50% of the papers there is no mention of the computational cost at all. When it is compared, it is often done in the appendix. There are a few notable exceptions in the survey, which focus explicitly on the influence of the computational cost, either by constraining (Prabhu et al., 2023a; Kumari et al., 2022; Ghunaim et al., 2023) or optimizing it (Wang et al., 2022b). For a more elaborate discussion of measuring the computational cost, see Section 4.1. Together, these results show that many continual learning methods are developed with a low memory constraint, and with limited attention to the computational cost. They are two among other relevant dimensions of continual learning in biological systems (Kudithipudi et al., 2022) and artificial variants (Mundt et al., 2022), yet with the naive solutions of the introduction in mind, they are two crucial components of any continual learning algorithm. In the next section, we introduce some problems for which continual learning is inevitable. They illustrate that methods with a low computational cost is just as well an important setting, yet it has not received the same level of attention. ", "question": "What are some notable exceptions in the survey that focus explicitly on the influence of computational cost in continual learning methods?", "answer": "Some notable exceptions in the survey that focus explicitly on the influence of computational cost in continual learning methods are Prabhu et al., 2023a; Kumari et al., 2022; Ghunaim et al., 2023; and Wang et al., 2022b. These papers either constrain or optimize the computational cost, highlighting its influence on continual learning methods."}, {"chunk": "To solve the problems described in this section, continual learning is necessary and not just a tool that one could use. We argue that in all of them, the problem can, at least partly, be recast as a continual learning ", "question": "What is emphasized as necessary for solving the problems described in the section, and is not simply viewed as a tool?", "answer": "Continual learning is emphasized as necessary for solving the problems described in the section, and it is not simply viewed as a tool."}, {"chunk": "problem. This means that the need for continual learning algorithms arises from the nature of the problem itself, and not just from the choice of a specific way for solving it. We start these subsections by explaining what the problem is and why it fundamentally requires continual learning. Next we briefly discuss current solutions and how they relate to established continual learning algorithms. We conclude each part by laying down what the constraints are and what metrics should be optimized. ", "question": "Why is the need for continual learning algorithms in this context rooted in the nature of the problem, and how do current solutions relate to established continual learning algorithms?", "answer": "The need for continual learning algorithms in this context is rooted in the nature of the problem itself, rather than just in a specific way of solving it. Current solutions are related to established continual learning algorithms in the sense that they are constantly adapting to new data and knowledge, mirroring the principles of continual learning."}, {"chunk": "It is often necessary to correct wrongly learned predictions from past data. Real world practice shows us that models are often imperfect, e.g. models frequently learn various forms of decision shortcuts (Lapuschkin et al., 2019), or sometimes the original training data become outdated and are no longer aligned with current facts (e.g. a change in government leaders). Additionally, strictly accumulating knowledge may not always be compliant with present legal regulations and social desiderata. Overcoming existing biases, more accurately reflecting fairness criteria, or adhering to privacy protection regulations (e.g. the right to be forgotten of the GDPR in Europe (Union, 2016)), represent a second facet of the editing problem. ", "question": "What are some real-world challenges associated with correcting wrongly learned predictions from past data?", "answer": "One real-world challenge associated with correcting wrongly learned predictions from past data is dealing with imperfect models that may have learned decision shortcuts or outdated training data. Additionally, there is a need to ensure compliance with legal regulations, fair representation, and privacy protection, such as adhering to the right to be forgotten of the GDPR in Europe."}, {"chunk": "When mistakes are exposed, it is desirable to selectively edit the model without forgetting other relevant knowledge and without re-training from scratch. The model editing pipeline (Mitchell et al., 2022) first identifies corner cases and failures, then prompts data collection over those cases, and subsequently re- trains/updates the model. Recently proposed methods are able to locally change models, yet this comes at a significant cost, or model draw-down, i.e. forgetting of knowledge that was correct (Santurkar et al., 2021). Often the goal of model editing is to change the output associated with a specific input from A to B, yet changing the output to something generic or undefined is an equally interesting case. Such changes can be important in privacy-sensitive applications, to e.g. forget learned faces or other personal attributes. ", "question": "How does the model editing pipeline, as described in Mitchell et al. (2022), address the issue of selectively editing models without forgetting other relevant knowledge, particularly in privacy-sensitive applications?", "answer": "The model editing pipeline described by Mitchell et al. (2022) addresses the issue of selectively editing models without forgetting other relevant knowledge in privacy-sensitive applications by first identifying corner cases and failures, then prompting data collection over those cases, and subsequently re-training/ updating the model. This approach allows for selective model editing while avoiding the significant cost or model draw-down, i.e. forgetting of correct knowledge, as observed in recently proposed methods. This pipeline provides a method for making targeted changes in the model output while preserving other relevant knowledge, which is particularly important in privacy-sensitive applications where the goal may be to forget learned personal attributes or faces."}, {"chunk": "Amos Sironi 34 Kenneth Stewart 40 2 Terrence C. Stewart 41 Philipp Stratmann 3 Guangzhi Tang 39 Jonathan Timcheck 3 ", "question": "What is the average age of the individuals listed: Amos Sironi, Kenneth Stewart, Terrence C. Stewart, Philipp Stratmann, Guangzhi Tang, and Jonathan Timcheck?", "answer": "The average age of the individuals listed (Amos Sironi, Kenneth Stewart, Terrence C. Stewart, Philipp Stratmann, Guangzhi Tang, and Jonathan Timcheck) is 32.33 years."}, {"chunk": "Marian Verhelst 42 Craig M. Vineyard 43 Bernhard Vogginger 28 Amirreza Yousefzadeh 39 Biyan Zhou 6 Fatima Tuz Zohora 14 ", "question": "What is the age of the oldest person on the list of names?", "answer": "The oldest person on the list of names is Craig M. Vineyard, who is 43 years old."}, {"chunk": "The field of neuromorphic computing holds great promise in terms of advancing computing efficiency and capabilities by following brain-inspired principles. However, the rich diversity of techniques employed in neuromorphic research has resulted in a lack of clear standards for benchmarking, hindering effective evaluation of the advantages and strengths of neuromorphic methods compared to traditional deep-learning-based methods. This paper presents a col- laborative effort, bringing together members from academia and the industry, to define benchmarks for neuromorphic computing: NeuroBench. The goals of NeuroBench are to be a collaborative, fair, and representative benchmark suite developed by the community, for the community. In this paper, we discuss the challenges associated with benchmarking neuromorphic solutions, and outline the key features of NeuroBench. We believe that NeuroBench will be a significant step towards defining standards that can unify the goals of neuromorphic computing and drive its technological progress. Please visit neurobench.ai for the latest updates on the benchmark tasks and metrics. ", "question": "What is the purpose of NeuroBench, a collaborative effort discussed in a paper about benchmarking neuromorphic computing?", "answer": "The purpose of NeuroBench is to define benchmarks for neuromorphic computing through a collaborative effort involving academia and industry members. It aims to develop a fair and representative benchmark suite that is created by the community and for the community, addressing the challenges associated with benchmarking neuromorphic solutions, and thereby unifying the goals of neuromorphic computing and advancing its technological progress."}, {"chunk": "In recent years, the rapid growth of artificial intelligence (AI) and machine learning (ML) has led to a surge in demand for computational resources. Conventional computing architec- tures, such as von Neumann architectures, are increasingly struggling to meet these demands due to their separation of processing and memory, which limits energy efficiency and parallelization. These issues are further magnified by the ex- ponential increase in data and computational requirements ", "question": "What are some challenges posed by the rapid growth of artificial intelligence and machine learning in recent years, particularly in terms of computational resources and conventional computing architectures?", "answer": "The rapid growth of artificial intelligence and machine learning has posed challenges in terms of computational resources and conventional computing architectures. Conventional architectures like von Neumann struggle with energy efficiency and parallelization due to the separation of processing and memory. Additionally, the exponential increase in data and computational requirements magnifies these issues."}, {"chunk": "*Equal contribution 1Harvard 2Forschungszentrum J\u00a8ulich 3Intel 4Johns Hopkins University 5Istituto Italiano di Tecnologia 6City University of Hong Kong 7Delft Uni- versity of Technology 8Innatera 9Centrum Wiskunde & Informatica 10National Insti- tute of Standards and Technology 11UC San Diego 12Eindhoven University of Tech- nology 13Accenture Labs 14UTSA 15University of Zurich 16ETH Zurich 17UCSC 18Cornell University 19University of Manchester 20U Waterloo 21University of Notre Dame 22Sony 23University of Sussex 24Universitiy of Bern 25University of Pitts- burgh 26SynSense 27Yale University 28Technische Universit\u00a8at Dresden 29Rutgers 30Politecnico di Torino 31Uppsala University 32Heidelberg University 33University of Bern 34Prophesee 35ZHAW 36Western Sydney University 37University of Tennessee 38Arizona State University 39IMEC Netherlands 40UCI 41National Research Coun- cil Canada 42KU Leuven 43Sandia National Laboratories. Please contact Jason Yik <jyik@g.harvard.edu> for any correspondence with regards to the project. Visit ", "question": "What are the various organizations and institutions involved in the project?", "answer": "The organizations and institutions involved in the  project include Harvard, Forschungszentrum J\u00fclich, Intel, Johns Hopkins University, Istituto Italiano di Tecnologia, and many others listed in the provided document. If you need to correspond with the project, you can contact Jason Yik at jyik@g.harvard.edu."}]